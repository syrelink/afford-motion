name: CMDM

## modeling space
input_feats: -1
data_repr: 'pos'

## time embedding
time_emb_dim: 512

## conditions
## 1. contact
contact_model:
  contact_type: 'contact_cont_joints' # ['contact_one_joints', 'contact_all_joints', 'contact_cont_joints', 'contact_pelvis']
  contact_joints: [0, 10, 11, 12, 20, 21]

  planes: [32, 64, 128, 256]
  num_points: ${task.dataset.num_points}
  blocks: [2, 2, 2, 2]

## 2. text
text_model:
  version: 'ViT-B/32'
  max_length: 32

### model architecture
#arch: 'trans_enc'
#latent_dim: 512
#mask_motion: true
#num_layers: [1,1,1,1,1]
#num_heads: 8
#dropout: 0.1
#dim_feedforward: 1024

# 模型架构选择
arch: "trans_mamba"
# Mamba 相关参数
mamba_layers: 1       # 如果 num_layers 总和也是 8，则全用 Mamba；如果是 4，则前 4 层 Trans，后 4 层 Mamba
mamba_d_state: 16     # SSM 状态维度 (默认 16)
mamba_d_conv: 4       # 局部卷积核大小 (默认 4)
mamba_expand: 2       # 内部维度扩展倍数 (默认 2)
mamba_drop_path: 0.1  # Stochastic Depth (建议设为 0.1 提高泛化)

# 其他基础参数 (保持原 CMDM 设置)
latent_dim: 512
mask_motion: true
num_layers: [1,1,1,1,1]
num_heads: 8
dropout: 0.1
dim_feedforward: 1024

# =============================================================================
# DiT (Diffusion Transformer) 架构配置
# =============================================================================
# 使用方法: 将 arch 改为 'dit' 或 'dit_cross'
#
# arch: 'dit'           # 纯DiT: 使用AdaLN注入条件，条件通过cross-attn pooling融合
# arch: 'dit_cross'     # DiT+Cross: AdaLN + 每层对contact做cross-attention
#
# DiT 特有参数:
# dit_drop_path: 0.1              # Stochastic Depth rate (线性增长)
# dit_use_cross_attn_pooling: true  # 用cross-attention聚合contact特征 (仅dit)
#
# 推荐配置 (HumanML3D):
# arch: 'dit'
# latent_dim: 512
# num_layers: [1,1,1,1,1,1,1,1]   # 总共8层DiT blocks
# num_heads: 8
# dim_feedforward: 2048           # MLP ratio = 4
# dropout: 0.1
# dit_drop_path: 0.1
# =============================================================================