name: CMDM

## modeling space
input_feats: -1
data_repr: 'pos'

## time embedding
time_emb_dim: 512

## conditions
## 1. contact
contact_model:
  contact_type: 'contact_cont_joints' # ['contact_one_joints', 'contact_all_joints', 'contact_cont_joints', 'contact_pelvis']
  contact_joints: [0, 10, 11, 12, 20, 21]

  planes: [32, 64, 128, 256]
  num_points: ${task.dataset.num_points}
  blocks: [2, 2, 2, 2]

## 2. text
text_model:
  version: 'ViT-B/32'
  max_length: 32

### model architecture
## trans_mamba 配置（原始配置，已注释）
#arch: 'trans_mamba'
#latent_dim: 512
#mask_motion: true
#num_layers: [1,1,1,1,1]
#num_heads: 8
#dropout: 0.1
#dim_feedforward: 1024

## trans_enc 配置（原始配置，已注释）
#arch: 'trans_enc'
#latent_dim: 512
#mask_motion: true
#num_layers: [1,1,1,1,1]
#num_heads: 8
#dropout: 0.1
#dim_feedforward: 1024

# bimamba 配置（新增）
arch: 'bimamba'
latent_dim: 512
mask_motion: true
num_layers: [3, 2]  # 3层Transformer + 2层BiMamba
num_heads: 8
dim_feedforward: 1024
dropout: 0.15
mamba_layers: 2
mamba_d_state: 16
mamba_d_conv: 4
mamba_expand: 2
mamba_drop_path: 0.05



# # 模型架构选择 - DiT 稳定配置
# arch: "dit"

# # DiT 核心参数
# latent_dim: 512
# mask_motion: true

# # 层数配置（保持5层，不增加）
# num_layers: [1, 1, 1, 1, 1]

# # 注意力头数
# num_heads: 8

# # MLP 扩展倍数
# dim_feedforward: 1024

# # Dropout（增强正则化）
# dropout: 0.15

# # DiT 专用参数
# dit_drop_path: 0.05
# dit_use_cross_attn_pooling: true

# # 条件嵌入配置
# condition_embedder:
#   use_cross_attn_pooling: true
#   num_latents: 64
#   fusion_method: 'cross_attn'

# # 训练稳定性参数
# grad_clip: 1.0
# weight_decay: 1e-4
# warmup_steps: 2000
# lr_scheduler: 'cosine'

# # 早停配置
# early_stopping:
#   enabled: true
#   patience: 5
#   min_delta: 0.01

# # 评估配置
# eval_every_epochs: 20
# eval_num_samples: 500

# # 模型保存策略
# save_best: true
# best_metric: 'fid'


