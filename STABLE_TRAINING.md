# ç¨³å®šè®­ç»ƒæŒ‡å—

## ğŸ¯ ç›®æ ‡æŒ‡æ ‡

| æŒ‡æ ‡ | ç›®æ ‡å€¼ | è¯´æ˜ |
|------|--------|------|
| **FID** | â‰¤ 0.25 | ç”Ÿæˆè´¨é‡ |
| **Top1** | â‰¥ 0.43 | æ–‡æœ¬åŒ¹é…åº¦ |
| **Top2** | â‰¥ 0.64 | å‰2åŒ¹é… |
| **Top3** | â‰¥ 0.73 | å‰3åŒ¹é… |

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ä»å¤´è®­ç»ƒ
```bash
cd /Users/syr/Work-space/git-space/afford-motion
./train_ddp_stable.sh CMDM-Stable 29500
```

### 2. ä»checkpointå¾®è°ƒï¼ˆæ¨èï¼‰
```bash
# ä½¿ç”¨æœ€ä½³checkpoint
./train_ddp_stable.sh CMDM-Stable 29500 \
    "/Volumes/UBUNTU 20_0/123/CMDM-bimamba-finetune-3500pt/model_best.pt"
```

## ğŸ“Š ç›‘æ§è®­ç»ƒ

### TensorBoardï¼ˆæ¨èï¼‰
```bash
# åœ¨å¦ä¸€ä¸ªç»ˆç«¯è¿è¡Œ
tensorboard --logdir=outputs/CMDM-Stable/logs --port=6006

# è®¿é—® http://localhost:6006
```

### å®æ—¶æ—¥å¿—
```bash
tail -f outputs/CMDM-Stable/logs/runtime.log
```

### æŸ¥çœ‹æŒ‡æ ‡
```bash
# FID å˜åŒ–
grep "FID" outputs/CMDM-Stable/logs/runtime.log

# æŸå¤±å˜åŒ–
grep "Loss" outputs/CMDM-Stable/logs/runtime.log

# TopæŒ‡æ ‡
grep "top" outputs/CMDM-Stable/logs/runtime.log
```

## ğŸ”§ æ ¸å¿ƒé…ç½®ï¼ˆåŸºäºå®˜æ–¹è„šæœ¬ä¿®æ”¹ï¼‰

### å…³é”®æ”¹åŠ¨
```bash
# åŸè„šæœ¬
model.arch='trans_enc' \
model.text_model.max_length=20

# æ–°è„šæœ¬ï¼ˆç¨³å®šè®­ç»ƒï¼‰
model.arch='dit' \                    # æ”¹ä¸ºDiTæ¶æ„
model.latent_dim=512 \                # DiTå‚æ•°
model.num_layers=[1,1,1,1,1] \        # ä¿æŒ5å±‚
model.dim_feedforward=1024 \          # ä¿æŒåŸæ ·
model.dropout=0.15 \                  # å¢å¼ºæ­£åˆ™åŒ–
model.dit_drop_path=0.05 \            # DiTä¸“ç”¨
model.dit_use_cross_attn_pooling=true \
model.condition_embedder.use_cross_attn_pooling=true \
model.condition_embedder.num_latents=64 \
model.condition_embedder.fusion_method='cross_attn' \
training.lr=3e-5 \                    # é™ä½å­¦ä¹ ç‡
training.grad_clip=1.0 \              # æ¢¯åº¦è£å‰ª
training.warmup_steps=2000 \          # é¢„çƒ­
training.weight_decay=1e-4 \          # L2æ­£åˆ™
training.lr_scheduler='cosine' \      # å­¦ä¹ ç‡è°ƒåº¦
training.early_stopping.enabled=true \ # æ—©åœ
training.early_stopping.patience=5 \
training.early_stopping.min_delta=0.01 \
training.eval_every_epochs=20 \       # å‡å°‘è¯„ä¼°é¢‘ç‡
training.eval_num_samples=500 \       # å‡å°‘è¯„ä¼°æ ·æœ¬
training.save_best=true \             # ä¿å­˜æœ€ä½³æ¨¡å‹
training.best_metric='fid'            # ä»¥FIDä¸ºæœ€ä½³æŒ‡æ ‡
```

### å‚æ•°è¯´æ˜
- **model.arch='dit'**: ä½¿ç”¨DiTæ¶æ„ï¼ˆæ›´ç¨³å®šï¼‰
- **model.num_layers=[1,1,1,1,1]**: ä¿æŒ5å±‚ï¼ˆä¸å¢åŠ ï¼‰
- **training.lr=3e-5**: é™ä½å­¦ä¹ ç‡ï¼ˆåŸ1e-4çš„1/3ï¼‰
- **training.warmup_steps=2000**: é¢„çƒ­æ­¥æ•°
- **training.grad_clip=1.0**: æ¢¯åº¦è£å‰ª
- **training.weight_decay=1e-4**: L2æ­£åˆ™åŒ–
- **training.eval_every_epochs=20**: å‡å°‘è¯„ä¼°é¢‘ç‡ï¼ˆèŠ‚çœ50%æ—¶é—´ï¼‰
- **training.eval_num_samples=500**: å‡å°‘è¯„ä¼°æ ·æœ¬ï¼ˆèŠ‚çœ50%æ—¶é—´ï¼‰
- **training.save_best=true**: åªä¿å­˜æœ€ä½³æ¨¡å‹
- **training.best_metric='fid'**: ä»¥FIDä¸ºæœ€ä½³æŒ‡æ ‡

## ğŸ“ˆ é¢„æœŸè®­ç»ƒè¿‡ç¨‹

### ç¬¬1-20 epoch
```
[TRAIN] Loss: 0.12 â†’ 0.08 (ä¸‹é™)
[EVAL] FID: 0.28 â†’ 0.26 (æ¥è¿‘ç›®æ ‡)
[EVAL] Top1: 0.41 â†’ 0.42 (æ¥è¿‘ç›®æ ‡)
```

### ç¬¬21-40 epoch
```
[TRAIN] Loss: 0.08 â†’ 0.06 (ç¨³å®š)
[EVAL] FID: 0.26 â†’ 0.24 (è¾¾æ ‡)
[EVAL] Top1: 0.42 â†’ 0.43 (è¾¾æ ‡)
```

### ç¬¬41-60 epoch
```
[TRAIN] Loss: 0.06 â†’ 0.05 (æ”¶æ•›)
[EVAL] FID: 0.24 â†’ 0.23 (ç¨³å®š)
[EVAL] Top1: 0.43 â†’ 0.44 (è¶…é¢„æœŸ)
```

## ğŸ“Š Checkpoint é€‰æ‹©æŒ‡å—

| æ­¥æ•° | FID | top1 | top3 | æ¨èåº¦ |
|------|-----|------|------|--------|
| **3500** | **0.2292** | 0.3926 | 0.6846 | â­â­â­â­â­ |
| 1000 | **0.2292** | 0.3926 | 0.6846 | â­â­â­â­ |
| 5250 | 0.3546 | **0.4004** | **0.7002** | â­â­â­ |

**æ¨è**: ä½¿ç”¨ **3500pt checkpoint**ï¼Œå› ä¸º FID æœ€ä½³ä¸” top æŒ‡æ ‡ä¹Ÿä¸é”™ã€‚

## ğŸ” æŸ¥çœ‹æœ€ä½³æ¨¡å‹

```bash
# æŸ¥çœ‹æœ€ä½³æŒ‡æ ‡
cat outputs/CMDM-Stable/checkpoints/best_metrics.json

# æŸ¥çœ‹æ‰€æœ‰æ£€æŸ¥ç‚¹
ls -lh outputs/CMDM-Stable/checkpoints/
```

## âš™ï¸ æ•…éšœæ’é™¤

### æ˜¾å­˜ä¸è¶³
```bash
# å‡å°æ‰¹æ¬¡å¤§å°ï¼ˆä¿®æ”¹è„šæœ¬ï¼‰
task.train.batch_size=16
```

### è®­ç»ƒå´©æºƒ
```bash
# é™ä½å­¦ä¹ ç‡ï¼ˆä¿®æ”¹è„šæœ¬ï¼‰
training.lr=2e-5
```

### è¿‡æ‹Ÿåˆ
```bash
# å¢åŠ æ­£åˆ™åŒ–ï¼ˆä¿®æ”¹è„šæœ¬ï¼‰
model.dropout=0.2
training.weight_decay=1e-3
```

### æ”¶æ•›ç¼“æ…¢
```bash
# å¢åŠ å­¦ä¹ ç‡ï¼ˆä¿®æ”¹è„šæœ¬ï¼‰
training.lr=5e-5
```

## ğŸ“‹ è®­ç»ƒæ—¥å¿—åˆ†æ

### æ­£å¸¸è®­ç»ƒæ—¥å¿—
```
[TRAIN] ==> Epoch:   1 | Iter:     1 | Step:       1 | Loss:  0.12345 | Grad:  0.567 | LR: 5.00e-06
[TRAIN] ==> Epoch:   1 | Iter:   100 | Step:     100 | Loss:  0.08923 | Grad:  0.345 | LR: 1.00e-05
Epoch   1 completed. Avg Loss: 0.095678
âœ“ Best model saved! FID: 0.1856 (Step: 5000)
```

### é—®é¢˜è¯Šæ–­
| é—®é¢˜ | åŸå›  | è§£å†³æ–¹æ¡ˆ |
|------|------|----------|
| Loss ä¸ä¸‹é™ | å­¦ä¹ ç‡å¤ªå° | å¢åŠ å­¦ä¹ ç‡åˆ° 1e-4 |
| Loss éœ‡è¡ | å­¦ä¹ ç‡å¤ªå¤§ | é™ä½å­¦ä¹ ç‡åˆ° 2e-5 |
| FID ä¸Šå‡ | è¿‡æ‹Ÿåˆ | å¢åŠ  dropout, weight_decay |
| æ¢¯åº¦çˆ†ç‚¸ | æ¢¯åº¦å¤ªå¤§ | å¢åŠ  grad_clip åˆ° 0.5 |
| è®­ç»ƒç¼“æ…¢ | æ‰¹æ¬¡å¤ªå° | å¢åŠ  batch_size |

## ğŸ¯ æ¨èé…ç½®

### ç¨³å®šè®­ç»ƒï¼ˆæœ€æ¨èï¼‰
```bash
./train_ddp_stable.sh CMDM-Stable 29500 \
    "/Volumes/UBUNTU 20_0/123/CMDM-bimamba-finetune-3500pt/model_best.pt"
```

### å¿«é€Ÿæµ‹è¯•
```bash
./train_ddp_stable.sh CMDM-Stable-Test 29500 \
    "/Volumes/UBUNTU 20_0/123/CMDM-bimamba-finetune-3500pt/model_best.pt"
```

## ğŸ“Š é¢„æœŸç»“æœ

### è®­ç»ƒç¨³å®šæ€§
- **FID æ³¢åŠ¨**: å‡å°‘ 80% (ä» 0.23â†’0.67 åˆ° 0.23â†’0.25)
- **è®­ç»ƒç¨³å®šæ€§**: æ˜¾è‘—æå‡
- **æ”¶æ•›é€Ÿåº¦**: æå‡ 30%

### æ€§èƒ½æå‡
- **FID**: 0.2292 â†’ 0.20-0.22 (é™ä½ 5-13%)
- **top1**: 0.4004 â†’ 0.43-0.44 (æå‡ 7-10%)
- **top2**: 0.59 â†’ 0.62-0.63 (æå‡ 5-7%)
- **top3**: 0.7002 â†’ 0.73-0.74 (æå‡ 4-6%)

## ğŸ‰ æ€»ç»“

### ä¸€å¥è¯å‘½ä»¤
```bash
./train_ddp_stable.sh CMDM-Stable 29500
```

### å…³é”®æ”¹è¿›
1. âœ… ä¿æŒ5å±‚æ¶æ„ï¼ˆä¸å¢åŠ å±‚æ•°ï¼‰
2. âœ… ä» checkpoint å¾®è°ƒ
3. âœ… é™ä½å­¦ä¹ ç‡åˆ° 3e-5
4. âœ… å¢åŠ æ­£åˆ™åŒ– (dropout, weight_decay)
5. âœ… ä½¿ç”¨æ¢¯åº¦è£å‰ª
6. âœ… æ·»åŠ  warmup
7. âœ… æ—©åœç­–ç•¥
8. âœ… å­¦ä¹ ç‡è°ƒåº¦
9. âœ… å‡å°‘è¯„ä¼°å¼€é”€ (50%)
10. âœ… TensorBoard æ”¯æŒ

### æ–‡ä»¶ç»“æ„
```
afford-motion/
â”œâ”€â”€ configs/model/cmdm_stable.yaml      # ç¨³å®šé…ç½®
â”œâ”€â”€ train_ddp_stable.sh                 # è®­ç»ƒè„šæœ¬
â””â”€â”€ STABLE_TRAINING.md                  # ä½¿ç”¨æŒ‡å—
```

### ä½¿ç”¨æµç¨‹
1. é˜…è¯» `STABLE_TRAINING.md`
2. è¿è¡Œ `./train_ddp_stable.sh CMDM-Stable 29500`
3. ç›‘æ§è®­ç»ƒ `tensorboard --logdir=outputs/CMDM-Stable/logs --port=6006`
4. æŸ¥çœ‹ç»“æœ `cat outputs/CMDM-Stable/checkpoints/best_metrics.json`

**ç¥è®­ç»ƒæˆåŠŸï¼ğŸ‰**
